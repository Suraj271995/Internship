{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f7bd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/Main_Page'\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "headers = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])\n",
    "\n",
    "header_text = []\n",
    "\n",
    "for header in headers:\n",
    "    header_text.append(header.text.strip())\n",
    "\n",
    "df = pd.DataFrame({'Headers': header_text})\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8f8d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://presidentofindia.nic.in/former-presidents.htm'\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "presidents = []\n",
    "terms = []\n",
    "for row in soup.select('div.col-md-12 table tbody tr'):\n",
    "    columns = row.select('td')\n",
    "    name = columns[0].get_text()\n",
    "    term = columns[1].get_text()\n",
    "    presidents.append(name)\n",
    "    terms.append(term)\n",
    "\n",
    "df = pd.DataFrame({'Name': presidents, 'Term of Office': terms})\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3d95cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "team_url = 'https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "batsman_url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting'\n",
    "bowler_url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling'\n",
    "\n",
    "team_response = requests.get(team_url)\n",
    "batsman_response = requests.get(batsman_url)\n",
    "bowler_response = requests.get(bowler_url)\n",
    "\n",
    "team_soup = BeautifulSoup(team_response.content, 'html.parser')\n",
    "batsman_soup = BeautifulSoup(batsman_response.content, 'html.parser')\n",
    "bowler_soup = BeautifulSoup(bowler_response.content, 'html.parser')\n",
    "\n",
    "teams = []\n",
    "matches = []\n",
    "points = []\n",
    "ratings = []\n",
    "for row in team_soup.select('table.table tbody tr')[:10]:\n",
    "    columns = row.select('td')\n",
    "    team = columns[1].select('span')[1].get_text().strip()\n",
    "    teams.append(team)\n",
    "    match = columns[2].get_text()\n",
    "    matches.append(match)\n",
    "    point = columns[3].get_text()\n",
    "    points.append(point)\n",
    "    rating = columns[4].get_text()\n",
    "    ratings.append(rating)\n",
    "\n",
    "team_df = pd.DataFrame({'Team': teams, 'Matches': matches, 'Points': points, 'Rating': ratings})\n",
    "\n",
    "batsmen = []\n",
    "teams = []\n",
    "ratings = []\n",
    "for row in batsman_soup.select('table.table tbody tr')[:10]:\n",
    "    columns = row.select('td')\n",
    "    batsman = columns[1].select('a')[0].get_text().strip()\n",
    "    batsmen.append(batsman)\n",
    "    team = columns[1].select('span')[1].get_text().strip()\n",
    "    teams.append(team)\n",
    "    rating = columns[3].get_text()\n",
    "    ratings.append(rating)\n",
    "\n",
    "batsman_df = pd.DataFrame({'Batsman': batsmen, 'Team': teams, 'Rating': ratings})\n",
    "\n",
    "bowlers = []\n",
    "teams = []\n",
    "ratings = []\n",
    "for row in bowler_soup.select('table.table tbody tr')[:10]:\n",
    "    columns = row.select('td')\n",
    "    bowler = columns[1].select('a')[0].get_text().strip()\n",
    "    bowlers.append(bowler)\n",
    "    team = columns[1].select('span')[1].get_text().strip()\n",
    "    teams.append(team)\n",
    "    rating = columns[3].get_text()\n",
    "    ratings.append(rating)\n",
    "\n",
    "bowler_df = pd.DataFrame({'Bowler': bowlers, 'Team': teams, 'Rating': ratings})\n",
    "\n",
    "print('Top 10 ODI Teams:')\n",
    "print(team_df)\n",
    "print()\n",
    "print('Top 10 ODI Batsmen:')\n",
    "print(batsman_df)\n",
    "print()\n",
    "print('Top 10 ODI Bowlers:')\n",
    "print(bowler_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff1e65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "team_url = 'https://www.icc-cricket.com/rankings/womens/team-rankings/odi'\n",
    "batswoman_url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting'\n",
    "allrounder_url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder'\n",
    "\n",
    "team_response = requests.get(team_url)\n",
    "batswoman_response = requests.get(batswoman_url)\n",
    "allrounder_response = requests.get(allrounder_url)\n",
    "\n",
    "team_soup = BeautifulSoup(team_response.content, 'html.parser')\n",
    "batswoman_soup = BeautifulSoup(batswoman_response.content, 'html.parser')\n",
    "allrounder_soup = BeautifulSoup(allrounder_response.content, 'html.parser')\n",
    "\n",
    "teams = []\n",
    "matches = []\n",
    "points = []\n",
    "ratings = []\n",
    "for row in team_soup.select('table.table tbody tr')[:10]:\n",
    "    columns = row.select('td')\n",
    "    team = columns[1].select('span')[1].get_text().strip()\n",
    "    teams.append(team)\n",
    "    match = columns[2].get_text()\n",
    "    matches.append(match)\n",
    "    point = columns[3].get_text()\n",
    "    points.append(point)\n",
    "    rating = columns[4].get_text()\n",
    "    ratings.append(rating)\n",
    "\n",
    "team_df = pd.DataFrame({'Team': teams, 'Matches': matches, 'Points': points, 'Rating': ratings})\n",
    "\n",
    "batswomen = []\n",
    "teams = []\n",
    "ratings = []\n",
    "for row in batswoman_soup.select('table.table tbody tr')[:10]:\n",
    "    columns = row.select('td')\n",
    "    batswoman = columns[1].select('a')[0].get_text().strip()\n",
    "    batswomen.append(batswoman)\n",
    "    team = columns[1].select('span')[1].get_text().strip()\n",
    "    teams.append(team)\n",
    "    rating = columns[3].get_text()\n",
    "    ratings.append(rating)\n",
    "\n",
    "batswoman_df = pd.DataFrame({'Batswoman': batswomen, 'Team': teams, 'Rating': ratings})\n",
    "\n",
    "allrounders = []\n",
    "teams = []\n",
    "ratings = []\n",
    "for row in allrounder_soup.select('table.table tbody tr')[:10]:\n",
    "    columns = row.select('td')\n",
    "    allrounder = columns[1].select('a')[0].get_text().strip()\n",
    "    allrounders.append(allrounder)\n",
    "    team = columns[1].select('span')[1].get_text().strip()\n",
    "    teams.append(team)\n",
    "    rating = columns[3].get_text()\n",
    "    ratings.append(rating)\n",
    "\n",
    "allrounder_df = pd.DataFrame({'All-Rounder': allrounders, 'Team': teams, 'Rating': ratings})\n",
    "\n",
    "print('Top 10 ODI Women’s Teams:')\n",
    "print(team_df)\n",
    "print()\n",
    "print('Top 10 ODI Women’s Batswomen:')\n",
    "print(batswoman_df)\n",
    "print()\n",
    "print('Top 10 ODI Women’s Bowlers:')\n",
    "print(bowler_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2607f1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.cnbc.com/world/?region=world'\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "headlines = []\n",
    "times = []\n",
    "links = []\n",
    "for article in soup.select('div.Card-textContainer'):\n",
    "    headline = article.select('a.Card-title')[0].get_text().strip()\n",
    "    headlines.append(headline)\n",
    "    time = article.select('time')[0]['datetime']\n",
    "    times.append(time)\n",
    "    link = article.select('a.Card-title')[0]['href']\n",
    "    links.append(link)\n",
    "\n",
    "df = pd.DataFrame({'Headline': headlines, 'Time': times, 'NewsLink': links})\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41404729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles'\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "titles = []\n",
    "authors = []\n",
    "dates = []\n",
    "urls = []\n",
    "for article in soup.select('div.most-downloaded-articles-item'):\n",
    "    title = article.select('a.most-downloaded-articles-link')[0].get_text().strip()\n",
    "    titles.append(title)\n",
    "    author = article.select('div.js-multiple-authors')[0].get_text().strip()\n",
    "    authors.append(author)\n",
    "    date = article.select('span.js-article-date')[0].get_text().strip()\n",
    "    dates.append(date)\n",
    "    url = article.select('a.most-downloaded-articles-link')[0]['href']\n",
    "    urls.append(url)\n",
    "\n",
    "df = pd.DataFrame({'Paper Title': titles, 'Authors': authors, 'Published Date': dates, 'Paper URL': urls})\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cce191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.dineout.co.in/delhi-restaurants'\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "restaurants = []\n",
    "for restaurant in soup.select('h2.restnt-name'):\n",
    "    name = restaurant.get_text().strip()\n",
    "    restaurants.append(name)\n",
    "\n",
    "df = pd.DataFrame({'Restaurant Name': restaurants})\n",
    "\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
